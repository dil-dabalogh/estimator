# Estimation Orchestrator Configuration File
# Copy this file to orchestrator.conf and fill in your values
# Environment variables override values in this file

[provider]
# Choose LLM provider: "openai" or "bedrock"
provider = openai

[openai]
# OpenAI API key (or set OPENAI_API_KEY environment variable)
api_key = your-openai-api-key-here

# Model to use (default: gpt-5)
model = gpt-5

# Temperature for generation (0.0-2.0, default: 0.2)
temperature = 0.2

[bedrock]
# AWS region (or set AWS_REGION environment variable)
region = us-west-2

# For direct model invocation, specify model ID:
model = anthropic.claude-3-sonnet-20240229-v1:0

# OR for Bedrock Agent invocation, specify agent IDs:
# agent_id = YOUR_AGENT_ID
# agent_alias_id = YOUR_ALIAS_ID

# Temperature for generation (0.0-1.0, default: 0.2)
temperature = 0.2

# Note: AWS credentials are configured via:
# - AWS SSO: aws sso login --profile <profile> then export AWS_PROFILE=<profile>
# - Environment variables: AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
# - AWS profile: export AWS_PROFILE=<profile-name>
# - IAM role (when running on EC2/ECS/Lambda)

[atlassian]
# Atlassian/Confluence configuration
# These can also be set via environment variables:
# ATLASSIAN_URL, ATLASSIAN_USER_EMAIL, ATLASSIAN_API_TOKEN

url = https://your-domain.atlassian.net/wiki
email = you@company.com
token = your-atlassian-api-token-here

